<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>Spark Editor</title>

  <meta name="viewport" content="width=device-width, height=device-height, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="format-detection" content="telephone=no">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="57x57" href="icons/57x57.png">
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="icons/72x72.png">
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="icons/114x114.png">
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="icons/144x144.png">
  <link href='http://fonts.googleapis.com/css?family=Ubuntu:300,400' rel='stylesheet' type='text/css'>

  <style>
    html, body {
	  height: 100%;
      margin: 0;
      /*background: red;*/
	  /*overflow: hidden;*/
    }

    #content {
	  margin: 0;
	  width: 100%;
	  height: 100%;
      /*min-height: 100%;*/
	  background: rgb(66,84,102);
    }

	
	#loadingImg {
		position:absolute;
		top:0;
		left:0;
		right:0;
		bottom:0;
		margin:auto;
	}
   
  </style>
</head>
<body>
<script>
      // These will be initialized later
      var recognizer, recorder, callbackManager, audioContext, outputContainer;
      // Only when both recorder and recognizer do we have a ready application
      var recorderReady = recognizerReady = false;

      // A convenience function to post a message to the recognizer and associate
      // a callback to its response
      function postRecognizerJob(message, callback) {
        var msg = message || {};
        if (callbackManager) msg.callbackId = callbackManager.add(callback);
        if (recognizer) recognizer.postMessage(msg);
      };

      // This function initializes an instance of the recorder
      // it posts a message right away and calls onReady when it
      // is ready so that onmessage can be properly set
      function spawnWorker(workerURL, onReady) {
          recognizer = new Worker(workerURL);
          recognizer.onmessage = function(event) {
            onReady(recognizer);
          };
          recognizer.postMessage('');
      };

      // To display the hypothesis sent by the recognizer
      function updateHyp(data) {
        //if (outputContainer) outputContainer.innerHTML = hyp;
		//console.error("SAID: " + hyp);
		window.hyp=data.hyp;
		window.hypseg=data.hypseg;
		console.error(data.hyp);
      };

	  
	  
      // This updates the UI when the app might get ready
      // Only when both recorder and recognizer are ready do we enable the buttons
      function updateUI() {
        if (recorderReady && recognizerReady) startRecording(); //startBtn.disabled = stopBtn.disabled = false;
      };

      // This is just a logging window where we display the status
      function updateStatus(newStatus) {
        //document.getElementById('current-status').innerHTML += "<br/>" + newStatus;
      };

      // A not-so-great recording indicator
      function displayRecording(display) {
        //if (display) document.getElementById('recording-indicator').innerHTML = "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;";
        //else document.getElementById('recording-indicator').innerHTML = "";
      };

      // Callback function once the user authorises access to the microphone
      // in it, we instanciate the recorder
      function startUserMedia(stream) {
        var input = audioContext.createMediaStreamSource(stream);
        // Firefox hack https://support.mozilla.org/en-US/questions/984179
        window.firefox_audio_hack = input; 
        var audioRecorderConfig = {errorCallback: function(x) {updateStatus("Error from recorder: " + x);}};
        recorder = new AudioRecorder(input, audioRecorderConfig);
        // If a recognizer is ready, we pass it to the recorder
        if (recognizer) recorder.consumers = [recognizer];
        recorderReady = true;
        updateUI();
        updateStatus("Audio recorder ready");
      };

      // This starts recording. We first need to get the id of the grammar to use
      var startRecording = function() {
        var id = 0;//document.getElementById('grammars').value;
        if (recorder && recorder.start(id)) displayRecording(true);
      };

      // Stops recording
      var stopRecording = function() {
        recorder && recorder.stop();
        displayRecording(false);
      };

      // Called once the recognizer is ready
      // We then add the grammars to the input select tag and update the UI
      var recognizerReady = function() {
           //updateGrammars();
           recognizerReady = true;
           updateUI();
           updateStatus("Recognizer ready");
      };

      // We get the grammars defined below and fill in the input select tag
      var updateGrammars = function() {
        var selectTag = document.getElementById('grammars');
        for (var i = 0 ; i < grammarIds.length ; i++) {
            var newElt = document.createElement('option');
            newElt.value=grammarIds[i].id;
            newElt.innerHTML = grammarIds[i].title;
            selectTag.appendChild(newElt);
        }                          
      };

      // This adds a grammar from the grammars array
      // We add them one by one and call it again as
      // a callback.
      // Once we are done adding all grammars, we can call
      // recognizerReady()
      var feedGrammar = function(g, index, id) {
        if (id && (grammarIds.length > 0)) grammarIds[0].id = id.id;
        if (index < g.length) {
          grammarIds.unshift({title: g[index].title})
	  postRecognizerJob({command: 'addGrammar', data: g[index].g},
                             function(id) {feedGrammar(grammars, index + 1, {id:id});});
        } else {
          recognizerReady();
        }
      };

      // This adds words to the recognizer. When it calls back, we add grammars
      var feedWords = function(words) {
           postRecognizerJob({command: 'addWords', data: words},
                        function() {feedGrammar(grammars, 0);});
      };

      // This initializes the recognizer. When it calls back, we add words
      var initRecognizer = function() {
          // You can pass parameters to the recognizer, such as : {command: 'initialize', data: [["-hmm", "my_model"], ["-fwdflat", "no"]]}
          postRecognizerJob({command: 'initialize'},
                            function() {
                                        if (recorder) recorder.consumers = [recognizer];
                                        feedWords(wordList);});
      };

      // When the page is loaded, we spawn a new recognizer worker and call getUserMedia to
      // request access to the microphone
      window.onload = function() {
        //outputContainer = document.getElementById("output");
        updateStatus("Initializing web audio and speech recognizer, waiting for approval to access the microphone");
        callbackManager = new CallbackManager();
        spawnWorker("js/recognizer.js", function(worker) {
            // This is the onmessage function, once the worker is fully loaded
            worker.onmessage = function(e) {
                // This is the case when we have a callback id to be called
                if (e.data.hasOwnProperty('id')) {
                  var clb = callbackManager.get(e.data['id']);
                  var data = {};
                  if ( e.data.hasOwnProperty('data')) data = e.data.data;
                  if(clb) clb(data);
                }
                // This is a case when the recognizer has a new hypothesis
                if (e.data.hasOwnProperty('hyp')) {
                  var newHyp = e.data.hyp;
                  if (e.data.hasOwnProperty('final') &&  e.data.final) newHyp = "Final: " + newHyp;
                  updateHyp(e.data);
                }
                // This is the case when we have an error
                if (e.data.hasOwnProperty('status') && (e.data.status == "error")) {
                  updateStatus("Error in " + e.data.command + " with code " + e.data.code);
                }
            };
            // Once the worker is fully loaded, we can call the initialize function
            initRecognizer();
        });

        // The following is to initialize Web Audio
        try {
          window.AudioContext = window.AudioContext || window.webkitAudioContext;
          navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
          window.URL = window.URL || window.webkitURL;
          audioContext = new AudioContext();
        } catch (e) {
          updateStatus("Error initializing Web Audio browser");
        }
        if (navigator.getUserMedia) navigator.getUserMedia({audio: true}, startUserMedia, function(e) {
                                        updateStatus("No live audio input in this browser");
                                    });
        else updateStatus("No web audio support in this browser");

      // Wiring JavaScript to the UI
	  /*
      var startBtn = document.getElementById('startBtn');
      var stopBtn = document.getElementById('stopBtn');
      startBtn.disabled = true;
      stopBtn.disabled = true;
      startBtn.onclick = startRecording;
      stopBtn.onclick = stopRecording;
	  */
      };

       // This is the list of words that need to be added to the recognizer
       // This follows the CMU dictionary format
      //var wordList = [["COCO", "K AO K AO"], ["TINE", "T AY N"], ["ISHKA", "IY SH K AE"], ["CRA", "K R AE"], ["AER", "EY R"], ["AA", "AA"], ["AE", "AE"], ["AH", "AH"], ["AO", "AO"], ["AW", "AW"], ["AY", "AY"], ["B", "B"], ["CH", "CH"], ["D", "D"], ["DH", "DH"], ["EH", "EH"], ["ER", "ER"], ["EY", "EY"], ["F", "F"], ["G", "G"], ["HH", "HH"], ["IH", "IH"], ["IY", "IY"], ["JH", "JH"], ["K", "K"], ["L", "L"], ["M", "M"], ["N", "N"], ["NG", "NG"], ["OW", "OW"], ["OY", "OY"], ["P", "P"], ["R", "R"], ["S", "S"], ["SH", "SH"], ["T", "T"], ["TH", "TH"], ["UH", "UH"], ["V", "V"], ["W", "W"], ["Y", "Y"], ["Z", "Z"], ["ZH", "ZH"],["ONE", "W AH N"], ["TWO", "T UW"], ["THREE", "TH R IY"], ["FOUR", "F AO R"], ["FIVE", "F AY V"], ["SIX", "S IH K S"], ["SEVEN", "S EH V AH N"], ["EIGHT", "EY T"], ["NINE", "N AY N"], ["ZERO", "Z IH R OW"]];
	  var wordList = [["PIDA", "P IY DH AE"], ["TINE", "L IY L IY"], ["ISHKA", "IY SH K AE"], ["CRA", "K AO K AO"], ["AER", "D AE D AE"], ["AA", "AA"], ["AE", "AE"], ["AH", "AH"], ["AO", "AO"], ["AW", "AW"], ["AY", "AY"], ["B", "B"], ["CH", "CH"], ["D", "D"], ["DH", "DH"], ["EH", "EH"], ["ER", "ER"], ["EY", "EY"], ["F", "F"], ["G", "G"], ["HH", "HH"], ["IH", "IH"], ["IY", "IY"], ["JH", "JH"], ["K", "K"], ["L", "L"], ["M", "M"], ["N", "N"], ["NG", "NG"], ["OW", "OW"], ["OY", "OY"], ["P", "P"], ["R", "R"], ["S", "S"], ["SH", "SH"], ["T", "T"], ["TH", "TH"], ["UH", "UH"], ["V", "V"], ["W", "W"], ["Y", "Y"], ["Z", "Z"], ["ZH", "ZH"],["ONE", "W AH N"], ["TWO", "T UW"], ["THREE", "TH R IY"], ["FOUR", "F AO R"], ["FIVE", "F AY V"], ["SIX", "S IH K S"], ["SEVEN", "S EH V AH N"], ["EIGHT", "EY T"], ["NINE", "N AY N"], ["ZERO", "Z IH R OW"]];
	  //var wordList = [["PIDA", "P IY DH AE"], ["TINE", "L UW M EH"], ["ISHKA", "AE G UW AH"], ["CRA", "T EH R AA"], ["AER", "V EH N T OW"], ["AA", "AA"], ["AE", "AE"], ["AH", "AH"], ["AO", "AO"], ["AW", "AW"], ["AY", "AY"], ["B", "B"], ["CH", "CH"], ["D", "D"], ["DH", "DH"], ["EH", "EH"], ["ER", "ER"], ["EY", "EY"], ["F", "F"], ["G", "G"], ["HH", "HH"], ["IH", "IH"], ["IY", "IY"], ["JH", "JH"], ["K", "K"], ["L", "L"], ["M", "M"], ["N", "N"], ["NG", "NG"], ["OW", "OW"], ["OY", "OY"], ["P", "P"], ["R", "R"], ["S", "S"], ["SH", "SH"], ["T", "T"], ["TH", "TH"], ["UH", "UH"], ["V", "V"], ["W", "W"], ["Y", "Y"], ["Z", "Z"], ["ZH", "ZH"],["ONE", "W AH N"], ["TWO", "T UW"], ["THREE", "TH R IY"], ["FOUR", "F AO R"], ["FIVE", "F AY V"], ["SIX", "S IH K S"], ["SEVEN", "S EH V AH N"], ["EIGHT", "EY T"], ["NINE", "N AY N"], ["ZERO", "Z IH R OW"]];
      // This grammar recognizes digits
      //var grammarSpells = {numStates: 3, start: 0, end: 2, transitions: [{from: 0, to: 1, word: "COCO"},{from: 1, to: 0, word: "TINE"},{from: 1, to: 0, word: "ISHKA"},{from: 1, to: 0, word: "CRA"},{from: 1, to: 0, word: "AER"},{from: 0, to: 0, word: "ONE"},{from: 0, to: 0, word: "TWO"},{from: 0, to: 0, word: "THREE"},{from: 0, to: 0, word: "FOUR"},{from: 0, to: 0, word: "FIVE"},{from: 0, to: 0, word: "SIX"},{from: 0, to: 0, word: "SEVEN"},{from: 0, to: 0, word: "EIGHT"},{from: 0, to: 0, word: "NINE"},{from: 0, to: 0, word: "ZERO"}]};
	  var grammarSpells = {numStates: 1, start: 0, end: 0, transitions: [{from: 0, to: 0, word: "PIDA"},{from: 0, to: 0, word: "TINE"},{from: 0, to: 0, word: "ISHKA"},{from: 0, to: 0, word: "CRA"},{from: 0, to: 0, word: "AER"},{from: 0, to: 0, word: "ONE"},{from: 0, to: 0, word: "TWO"},{from: 0, to: 0, word: "THREE"},{from: 0, to: 0, word: "FOUR"},{from: 0, to: 0, word: "FIVE"},{from: 0, to: 0, word: "SIX"},{from: 0, to: 0, word: "SEVEN"},{from: 0, to: 0, word: "EIGHT"},{from: 0, to: 0, word: "NINE"},{from: 0, to: 0, word: "ZERO"}]};
      var grammars = [{title: "Spells", g: grammarSpells}];
      var grammarIds = [];
    </script>
    <!-- These are the two JavaScript files you must load in the HTML,
    The recognizer is loaded through a Web Worker -->
    <script src="js/audioRecorder.js"></script>
    <script src="js/callbackManager.js"></script>
	
	
<!-- Main Content Div -->
<div id="content"></div>
	
<!-- Loading Image -->
<img id="loadingImg" src="Loading.png"/>

<!-- remote skc url -->
<script>function getMainSparkClientUrl(){
var queryDict = {};
location.search.substr(1).split("&").forEach(function(item) {queryDict[item.split("=")[0]] = item.split("=")[1]});
return queryDict.skc;} </script>

<!-- remove Loading Image -->
<script>function hideLoadingImage(){
var element = document.getElementById("loadingImg");
element.parentNode.removeChild(element);
} </script>

<!-- Flambe -->
<script src="flambe.js"></script>
<script>
  flambe.embed(["targets/main-html.js"], "content");
</script>

</body>
</html>
